{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1764a938",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "mnli_baseline_files = [\n",
    "    \"20251111_162712-mnli_baseline-1/eval_predictions.jsonl\",\n",
    "    \"20251111_193408-mnli_baseline-2/eval_predictions.jsonl\",\n",
    "    \"20251111_223025-mnli_baseline-3/eval_predictions.jsonl\"\n",
    "]\n",
    "\n",
    "def combine_eval_predicitons(files):\n",
    "    dfs = []\n",
    "    for f in files:\n",
    "        parsed_path = parse_eval_path(f)\n",
    "        df = pd.read_json(f, lines=True)\n",
    "        df['date'] = parsed_path['date']\n",
    "        df['time'] = parsed_path['time']\n",
    "        df['model'] = parsed_path['model']\n",
    "        df['seed'] = parsed_path['seed']\n",
    "        dfs.append(df)\n",
    "    all_df = pd.concat(dfs, ignore_index=True)\n",
    "    return all_df\n",
    "\n",
    "def parse_eval_path(path):\n",
    "    dir_name = os.path.dirname(path)\n",
    "    date_time, model_name, seed = dir_name.split(\"-\")\n",
    "    date_str, time_str = date_time.split(\"_\")\n",
    "    return {\n",
    "        \"date\": date_str,\n",
    "        \"time\": time_str,\n",
    "        \"model\": model_name,\n",
    "        \"seed\": seed\n",
    "    }\n",
    "\n",
    "def parse_eval_predictions(all_df):\n",
    "# 1) (Optional) ensure each pairID has all seeds\n",
    "    expected_seeds = sorted(all_df['seed'].unique())\n",
    "    pairs_with_all = (\n",
    "        all_df.groupby('pairID')['seed'].nunique()\n",
    "        .eq(len(expected_seeds))\n",
    "    )\n",
    "    all_df = all_df[all_df['pairID'].isin(pairs_with_all[pairs_with_all].index)]\n",
    "\n",
    "    # 2) pivot so each seed’s predictions share one row\n",
    "    base_cols = ['promptID','pairID','premise','hypothesis','genre','label']\n",
    "    wide = (\n",
    "        all_df\n",
    "        .pivot_table(index=base_cols,\n",
    "                    columns='seed',\n",
    "                    values=['predicted_label','predicted_scores'],\n",
    "                    aggfunc='first')\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    # flatten multiindex columns like ('predicted_label', '42') -> 'predicted_label_seed42'\n",
    "    wide.columns = [\n",
    "        f\"{c0}_seed{c1}\" if isinstance(c0, str) and c0.startswith('predicted_') else c0\n",
    "        for c0, c1 in (wide.columns if isinstance(wide.columns, pd.MultiIndex)\n",
    "                    else [(c, '') for c in wide.columns])\n",
    "    ]\n",
    "\n",
    "    # 3) count how many models were wrong on each row\n",
    "    pl_cols = [c for c in wide.columns if str(c).startswith('predicted_label_seed')]\n",
    "    wide['wrong_count'] = sum((wide[c] != wide['label']).astype(int) for c in pl_cols)\n",
    "\n",
    "    # 4) keep only rows all models got wrong\n",
    "    all_wrong = wide[wide['wrong_count'] == len(pl_cols)].copy()\n",
    "\n",
    "    # 5) (Optional) select only the columns you want to see\n",
    "    # Base columns + every seed’s predicted_label and predicted_scores + wrong_count\n",
    "    ps_cols = [c for c in wide.columns if str(c).startswith('predicted_scores_seed')]\n",
    "    final_cols = base_cols + pl_cols + ps_cols + ['wrong_count']\n",
    "    result = all_wrong[final_cols] \n",
    "    return result   \n",
    "\n",
    "def display_all_results(df):\n",
    "    with pd.option_context('display.max_rows', None, 'display.max_columns', None, 'display.max_colwidth', None):\n",
    "        display(df)\n",
    "        \n",
    "all_df = combine_eval_predicitons(mnli_baseline_files)\n",
    "hard_prompts = parse_eval_predictions(all_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9cca8df6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        genre  num_wrong\n",
      "0       slate        315\n",
      "1   telephone        252\n",
      "2     fiction        242\n",
      "3      travel        208\n",
      "4  government        171\n",
      "genre\n",
      "slate         0.053708\n",
      "telephone     0.042726\n",
      "fiction       0.040885\n",
      "travel        0.035088\n",
      "government    0.029306\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "genre_counts = (\n",
    "    hard_prompts[\"genre\"]\n",
    "    .value_counts()\n",
    "    .rename_axis(\"genre\")\n",
    "    .reset_index(name=\"num_wrong\")\n",
    "    .sort_values(\"num_wrong\", ascending=False)\n",
    ")\n",
    "\n",
    "print(genre_counts)\n",
    "\n",
    "genre_rate = (\n",
    "    hard_prompts.groupby(\"genre\").size() /\n",
    "    all_df.groupby(\"genre\").size()\n",
    ").sort_values(ascending=False)\n",
    "print(genre_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d64b125a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "promptID                   29445\n",
       "pairID                     29445\n",
       "premise                    29445\n",
       "premise_binary_parse       29445\n",
       "premise_parse              29445\n",
       "hypothesis                 29445\n",
       "hypothesis_binary_parse    29445\n",
       "hypothesis_parse           29445\n",
       "genre                      29445\n",
       "label                      29445\n",
       "predicted_scores           29445\n",
       "predicted_label            29445\n",
       "date                       29445\n",
       "time                       29445\n",
       "model                      29445\n",
       "seed                       29445\n",
       "dtype: int64"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "273db9eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "promptID                  1188\n",
       "pairID                    1188\n",
       "premise                   1188\n",
       "hypothesis                1188\n",
       "genre                     1188\n",
       "label                     1188\n",
       "predicted_label_seed1     1188\n",
       "predicted_label_seed2     1188\n",
       "predicted_label_seed3     1188\n",
       "predicted_scores_seed1    1188\n",
       "predicted_scores_seed2    1188\n",
       "predicted_scores_seed3    1188\n",
       "wrong_count               1188\n",
       "dtype: int64"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hard_prompts.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4d942a",
   "metadata": {},
   "outputs": [],
   "source": [
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
